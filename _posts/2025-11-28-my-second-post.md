---
title: "俺的第一篇知乎小记"
date: 2025-11-28 22:43:00 +0800
categories: [知乎, 小记]
tags: [知乎, 乱七八糟, LLM]
toc: true
description: "记录下刷知乎时学到的东西ovo"
comments: true
---

# 俺的第一篇知乎小记
因为刷知乎的时候从总能学到很多东西，所以向专门做个分类来记录在知乎中学习到的内容qaq顺便清清收藏夹

## Q1. 无大算力时，作为学生，LLM还有哪些值得做的研究？
**Cv大法代码酱**：

### 一、核心底层逻辑

摆脱“预训练大模型=LLM研究”的误区：大厂靠算力堆参数（70B+/千亿级），学生应把 **开源小模型**（如Llama-3-8B、7B级）当“解剖对象”，聚焦 **用巧劲解决具体问题** ，而非算力竞赛。

### 二、各研究方向
1. **数据中心AI（核心低算力方向）**

    （1）基于 Llama-3-8B，用Prompt工程/思维链（CoT）生成教科书级语料，标注并分析这类高质量语料的分布特征（比如句式结构、知识密度、错误率），对比普通互联网语料的差异。

    （2）复刻微软Phi系列思路，设计小样本数据筛选算法（比如基于语义相似度、知识准确性），用筛选后的10万级高质量数据训练7B模型，验证其在代码生成/数学推理任务上能否对标更大模型；

    （3）研究“小模型生成合成数据”的方法，比如让7B模型生成领域专属语料（如医学、法律），再用这些合成数据微调同量级模型，测试效果提升幅度。

2. **LLM评估（被低估且易落地）**

    （1）针对生成式任务（如文案创作、代码生成），设计替代BLEU/ROUGE的评估指标（比如结合人工标注+小模型打分的混合评估体系），解决传统指标失效问题；

    （2）验证MMLU/GSM8K榜单的“刷榜漏洞”，比如用小模型测试“数据泄露”对分数的影响，提出榜单防刷榜的轻量方案（如动态替换测试集样本）；

    （3）做RAG/Agent系统的自动化评估，比如设计覆盖“检索准确率、回答相关性、事实正确性”的多维度评估脚本，无需大算力，仅需标注少量测试用例。

3. **模型优化类（小模型为核心）**

    （1）推断时计算（Test-time Augmentation）：用7B模型，通过多轮对话、自我反思的Prompt设计，让其在推理任务（如GSM8K）上达到13B/70B模型的效果，量化“思考步数”与效果的关系；

    （2）高效微调：研究LoRA/QLoRA在小模型上的极致调优（比如不同秩值、微调数据量的影响），目标是用10%以内的算力，让7B模型在特定任务（如客服对话）上接近全量微调效果；

    （3）机械可解释性：拆解小模型（如Llama-3-8B）的Attention权重，分析“为什么模型会生成错误答案”，比如定位某几层Attention的决策偏差，提出轻量修正方案。

4. **Agent社会学模拟（交叉领域，低算力）**

    （1）基于LLM搭建“狼人杀游戏环境”，让多个Agent（用7B模型驱动）参与游戏，记录并分析Agent的沟通策略、角色协作、欺骗行为等涌现特征；

    （2）构建“模拟软件开发公司”场景，设计产品、开发、测试等不同角色的Agent，研究其分工协作中的问题（如信息传递偏差、任务拖延），提出Agent协作优化规则。

### 三、落地执行建议（具体到每日/每周动作）

1. **论文积累**：每天刷Hugging Face Daily Papers，每周精读1篇经典（如Phi系列、Simulacra of Creativity），梳理“别人的巧思”；

2. **代码实践**：每周抽半天读LangChain/LlamaIndex源码，聚焦“长文档切片边界”问题，尝试改1-2行代码优化；

3. **小实验落地**：选1个方向（如“小模型生成高质量语料”），用Colab免费算力跑通最小验证实验（比如生成1000条语料+简单分析），再逐步扩展。

### 四、自己补充学到的一些内容

1. 应当学习如何用小模型去清洗、筛选、合成高质量的数据，去喂给大模型，或者用高质量数据训练小模型达到大模型的效果

    关注 **微软Phi系列论文**。

    Phi-1 **Textbooks Are All You Need** :证明了只要数据质量足够高，哪怕只有1.3B参数的模型，也能在代码生成任务上打败几十倍大的模型。

    **背后的逻辑** : 现在的互联网语料充满了噪音和垃圾，模型花了大量算力去学习不需要学习的废话。如果你能研究出一套高效的数据筛选算法，或者利用现有 LLM 生成高质量合成数据 Synthetic Data 的方法，这本身就是顶级的科研成果。

2. 研究 **LLM-as-a-Judge**

    用大模型去评估小模型。这里面的偏差Bias怎么消除？位置偏差Position Bias怎么处理？模型是不是倾向于更长的回答？

    example：加州伯克利分校发布的 Chatbot Arena：引入了人类投票和Elo积分系统，但这个成本高

    作为一个学生，你可以去研究如何设计一套自动化、低成本且与人类偏好高度对齐的评估框架。

    比如，针对Agent任务，怎么评估它的规划能力？针对RAG，怎么评估它的召回准确率和生成忠实度？这不需要几百张卡，只需要你调用API或者跑个本地的7B模型就能做实验。**RAGAS** 这个项目就是一个很好的例子，它定义了一套针对RAG的评估指标，现在已经成了行业标准之一。

3. 可以看 **字节跳动RAG实践手册**

4. 研究 **Graph RAG**

    这涉及图神经网络GNN和LLM的融合。你完全可以在小规模数据集上验证你的想法，不需要跑全量的维基百科。

5. 真正的 Agent 研究

    探索大模型的认知边界。比如规划Planning能力。模型能不能真的像人一样拆解复杂任务？现在的ReAct、Tree of Thoughts这些框架，本质上是在用工程手段弥补模型推理能力的不足。

6. 读斯坦福著名的 Generative Agents

    它研究的不是模型本身，而是记忆Memory的架构。它设计了短期记忆、长期记忆、反思Reflection机制。作为一个学生，你完全可以复刻并改进这种架构。你可以研究 **怎么让Agent在长周期任务中保持一致性**，**怎么解决误差积累Error Propagation** 的问题。Agent一旦第一步错了，后面全错，有没有一种自我修正Self-Correction的机制？这不需要训练模型，需要的是 **设计精巧的认知架构** 。
    
7. 可以做高效微调 PEFT

    LoRA和QLoRA的出现就是为了解决大家穷的问题。但是LoRA就是终点吗？显然不是。现在的LoRA通常是 **全层或者特定层微调** ，你能不能研究出一种的 **动态的LoRA** ，根据输入样本的难易程度，自适应地选择微调哪些秩 Rank？或者研究 **LoRA在多任务学习下的表现，怎么解决灾难性遗忘Catastrophic Forgetting** ？

8. 可以做量化Quantization

    大家都知道4-bit量化，那能不能做2-bit？甚至1.58bit？最近微软出的 **BitNet b1.58** ,把权重压到了三元值{-1,0,1}，这直接挑战了Transformer的底层计算逻辑。虽然复现BitNet可能需要算力，但你可以研究现有的模型量化后的行为变化。比如量化会不会损害模型的逻辑推理能力？会不会更容易产生幻觉？这种关于 **模型行为学** 的研究，非常有价值。

9. 机械可解释性 Mechanistic Interpretability

    核心目标：搞清楚黑盒子里到底发生了什么。我们知道Transformer有Attention，有MLP，但具体的每一个神经元，每一个Attention Head在干什么？
    
    Anthropic：Induction Heads：专门复制上下文里的模式，是模型拥有上下文学习In-Context Learning能力的关键。*需要极其缜密的逻辑和数学直觉*

    **Neel Nanda** 有很多关于这方面的教程和工具库，比如 **TrnasformerLens** ，着绝对是宝藏。

10. 小模型的极限推理
    
    侧端模型On-device LLM才是未来的蓝海。
    
    如何在2B甚至1B的参数量下，保留模型的推理能力？这涉及到 **知识蒸馏Knowledge Distillation**。

    你可以研究怎么把 GPT-4 的推理过程蒸馏给一个极小的学生模型。不仅仅是蒸馏答案，而是蒸馏思维过程CoT。Google的Distilling Step-by-Step就是这方面的先驱。你可以尝试用更小的模型架构，比如SSM状态空间模型Mamba，或者RWKV，去在这个量级上挑战Transformer。这些非Transformer架构在长序列处理上有着天然的计算优势，而且训练成本相对较低，非常适合学生去探索。

11. 抓住一个具体的、反直觉的现象去深挖

    ex. 研究长上下文Long Context下的迷失现象。为什么把相关信息放在Prompt中间，模型就找不到了？这叫 **Lost in the Middle** 。你能不能通过改变位置编码，或者改变Attention Mask的方式来解决这个问题？又或者，你去研究 **对抗攻击Adversarial Attack** 。现在的LLM虽然经过了对齐，但依然很脆弱。你能不能找到一种通用的后缀，加在任何Prompt后面，就能让模型绕过安全检查？这叫 **Jailbreak**。这个领域的教科书：卡内基梅隆大学的 **Universal and Transferable Adversarial Attacks on Aligned Language Models** 。

12. 不要忽视了传统的NLP任务与LLM的结合。

    比如信息抽取information Extraction。你能不能研究一种 **少样本Few-shot的策略** ，让小模型在特定领域的抽取任务上达到大模型的效果？这在医疗、法律这些垂直领域非常有价值。垂直领域的微调和适配，是现在创业和落地最火的方向，作为学生，你可以找一个公开的法律文书数据集或者医疗问答数据集，去摸索一套Domain Adaptation的最佳实践。

13. 研究怎么用LLM来增强视觉理解

    现在的LLM可以生成代码，那能不能让它生成一段Python代码去调用OpenCV处理图片，然后再回答问题？这叫Visual Programming。这种Visual ChatGPT的思路，本质上是把视觉问题转化为了语言和逻辑问题，这恰恰避开了昂贵的视觉模型训练，而利用了LLM强大的规划能力。

14. System 1和System 2的融合

    System 1：直觉，是快思考，就是现在的LLM，给它一个Token，它预测下一个，这是本能。

    System 2：逻辑，是慢思考，是搜索，是规划。

    AlphaGo能赢是因为它有蒙特卡洛树搜索MCTS。现在的大模型缺乏这个。你能不能设计一种机制，让LLM在回答复杂问题时，不要急着输出，而是先在内部构建一颗思维树，进行搜索和剪枝，确定了路径再输出？这方面的研究，比如Tree of Thoughts，比如Reasoning via Planning，都是在尝试赋予模型System 2的能力。这不需要你重新训练模型，而是需要你在推断阶段Inference Time做文章。

15. Test-time Augmentation

    怎么利用一点推断时的算力，通过多轮对话、自我反思、多数投票，让一个7B模型的表现提升到13B甚至70B的水平？

16. Agent的社会学模拟

17. 多阅读

    arXiv，Hugging Face的Daily Papers、Simulacra of Creativity、看LangChain或者LlamaIndex的源码
